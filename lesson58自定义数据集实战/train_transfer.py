#-*- coding:utf-8 -*-import torchfrom torch import optim, nnimport visdomimport torchvisionfrom torch.utils.data import DataLoaderfrom pokeman import Pokemon# from resnet import ResNet18from torchvision.models import resnet18#可以直接加载训练好的模型from utils import Flattenbatchsz = 32lr = 1e-3epochs = 10device = torch.device('cuda')torch.manual_seed(1234)#保证实验能够复现train_db = Pokemon('Pokemon', 224, mode='train')val_db = Pokemon('Pokemon', 224, mode='val')test_db = Pokemon('Pokemon', 224, mode='test')train_loader = DataLoader(train_db, batch_size=batchsz, shuffle=True,                          num_workers=4)val_loader = DataLoader(val_db, batch_size=batchsz, shuffle=True,                          num_workers=2)test_loader = DataLoader(test_db, batch_size=batchsz, shuffle=True,                          num_workers=2)viz = visdom.Visdom()def evalute(model, loader):    correct = 0    total = len(loader.dataset)    for x,y in loader:        x, y = x.to(device), y.to(device)        with torch.no_grad():# 不需要梯度,将其加载到无梯度环境            logits = model(x)            pred = logits.argmax(dim=1)#选出最大的数        correct += torch.eq(pred, y).sum().float().item()#item()转换为numpy数据类型    return correct / totaldef main():    #############################################TransferLearning#######################################################    # model = ResNet18(5).to(device)    print('strated!')    trained_model = resnet18(pretrained=True)#已经训练好的model    print('model!')    model = nn.Sequential(*list(trained_model.children())[:-1],#将前17层取出# [b, 512, 1, 1], 只去0到最后一层,不把最后一层包括在里面        Flatten(),  # [b, 512,1,1]==>[b,512]        nn.Linear(512, 5)    )    # x = torch.randn(2, 3, 224, 224)    # print(model(x).shape)    print('model:', model)    # model = model.to(device)    #############################################TransferLearning#######################################################    optimizer = optim.Adam(model.parameters(), lr=lr)    criteon = nn.CrossEntropyLoss()#不需要经过softmax,只需要输出得到逻辑值    best_acc, best_epoch = 0, 0    global_step = 0    viz.line([0], [-1], win='loss', opts=dict(title='loss'))    viz.line([0], [-1], win='val_acc', opts=dict(title='val_acc'))    for epoch in range(epochs):        for step, (x, y) in enumerate(train_loader):            # x: [b, 3, 224, 224], y: [b]            x, y = x.to(device), y.to(device)            logits = model(x)            loss = criteon(logits, y)            optimizer.zero_grad()            loss.backward()            optimizer.step()            #         y的值,            viz.line([loss.item()], [global_step], win='loss', update='append')            global_step += 1        if epoch % 1 == 0:            val_acc = evalute(model, val_loader)            if val_acc > best_acc:                best_epoch = epoch                best_acc = val_acc                torch.save(model.state_dict(), 'best.mdl')#后缀名不影响使用                viz.line([val_acc], [global_step], win='val_acc', update='append')    print('best_acc:', best_acc, 'best_epoch:', best_epoch)    model.load_state_dict(torch.load('best.mdl'))    print('loaded from checkpoint!')    test_acc = evalute(model, test_loader)    print('test_acc:', test_acc)if __name__ == '__main__':    main()# best_acc: 0.8626609442060086 best_epoch: 2# loaded from checkpoint!# test_acc: 0.9055793991416309# 结果分析:# 1. 数据集数量小,每个类的较少;对于机器学习来说较多,但是对于DL来说,需要上万的数据规模# 2. 是否出现overfitting# import torch# from torch import optim, nn# import visdom# import torchvision# from torch.utils.data import DataLoader## from pokeman import Pokemon# # from    resnet import ResNet18# from torchvision.models import resnet18## from utils import Flatten## batchsz = 32# lr = 1e-3# epochs = 10## device = torch.device('cuda')# torch.manual_seed(1234)## train_db = Pokemon('pokemon', 224, mode='train')# val_db = Pokemon('pokemon', 224, mode='val')# test_db = Pokemon('pokemon', 224, mode='test')# train_loader = DataLoader(train_db, batch_size=batchsz, shuffle=True,#                           num_workers=4)# val_loader = DataLoader(val_db, batch_size=batchsz, num_workers=2)# test_loader = DataLoader(test_db, batch_size=batchsz, num_workers=2)## viz = visdom.Visdom()### def evalute(model, loader):#     model.eval()##     correct = 0#     total = len(loader.dataset)##     for x, y in loader:#         x, y = x.to(device), y.to(device)#         with torch.no_grad():#             logits = model(x)#             pred = logits.argmax(dim=1)#         correct += torch.eq(pred, y).sum().float().item()##     return correct / total### def main():#     # model = ResNet18(5).to(device)#     trained_model = resnet18(pretrained=True)#     model = nn.Sequential(*list(trained_model.children())[:-1],  # [b, 512, 1, 1]#                           Flatten(),  # [b, 512, 1, 1] => [b, 512]#                           nn.Linear(512, 5)#                           ).to(device)#     # x = torch.randn(2, 3, 224, 224)#     # print(model(x).shape)##     optimizer = optim.Adam(model.parameters(), lr=lr)#     criteon = nn.CrossEntropyLoss()##     best_acc, best_epoch = 0, 0#     global_step = 0#     viz.line([0], [-1], win='loss', opts=dict(title='loss'))#     viz.line([0], [-1], win='val_acc', opts=dict(title='val_acc'))#     for epoch in range(epochs):##         for step, (x, y) in enumerate(train_loader):#             # x: [b, 3, 224, 224], y: [b]#             x, y = x.to(device), y.to(device)##             model.train()#             logits = model(x)#             loss = criteon(logits, y)##             optimizer.zero_grad()#             loss.backward()#             optimizer.step()##             viz.line([loss.item()], [global_step], win='loss', update='append')#             global_step += 1##         if epoch % 1 == 0:##             val_acc = evalute(model, val_loader)#             if val_acc > best_acc:#                 best_epoch = epoch#                 best_acc = val_acc##                 torch.save(model.state_dict(), 'best.mdl')##                 viz.line([val_acc], [global_step], win='val_acc', update='append')##     print('best acc:', best_acc, 'best epoch:', best_epoch)##     model.load_state_dict(torch.load('best.mdl'))#     print('loaded from ckpt!')##     test_acc = evalute(model, test_loader)#     print('test acc:', test_acc)### if __name__ == '__main__':#     main()